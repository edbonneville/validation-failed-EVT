---
title: "Validation failed EVT"
author: "E. F. Bonneville"
date: "`r Sys.setenv(LANG = 'en_US.UTF-8'); format(Sys.Date(), '%d %B %Y')`"
output: 
  html_document:
    df_print: kable
    toc: yes
    toc_float: 
      smooth_scroll: false
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_knit$set(root.dir = here::here())
knitr::opts_chunk$set(
  echo = FALSE, 
  out.width = "100%", 
  warning = FALSE, 
  message = FALSE
)

# Load libraries for knitting
library(ggplot2)
library(targets)
library(tidyverse)
library(tableone)
library(rms)
library(glmnet)
library(DT)
```

```{r objs}
# Source functions
source("data-raw/prepare_raw_data.R")
source("R/imputation-helpers.R")
source("R/model-validation-helpers.R")
source("R/calplot-MI.R")

# Set contrasts for ordered factors
options(contrasts = rep("contr.treatment", 2))

# Set global setting
theme_set(theme_minimal(base_size = 14))

tar_load(
  c(
    dat_combined,
    dat_to_impute,
    imps_all,
    candidate_predictors,
    model_formula,
    analysis_settings,
    validation_dev_lambdamin,
    validation_comb_lambdamin
  )
)

# For later use
response_var <- all.vars(stats::update(model_formula, . ~ 1))
```

## Descriptives

### Table 1

For continuous variables:

```{r table-one-contin}
# Gives you everything for tables 1 and 2 (warnings due to variables not in validation, ignore!)
table_one <- dat_combined %>%  
  select(-all_of(c("sidescored", "AngleCcaIca", "ICAEAtherosclerosis", "StudySubjectID"))) %>%
  # Here we dichotomise purely for the table, does not affect original data
  mutate(
    ICA_nr_90orLarger_geq1 = factor(ifelse(ICA_nr_90orLarger >= 1, 1, 0)),
    ICA_nr_90orLarger_geq2 = factor(ifelse(ICA_nr_90orLarger >= 2, 1, 0)),
    ICAE_NASCET_99 = factor(ifelse(ICAE_NASCET_Degree < 99, 0,1)),
    InnCca_90orLarger_geq1 = factor(ifelse(InnCca_nr_90orLarger >= 1, 1, 0)),
    InnCca_90orLarger_geq2 = factor(ifelse(InnCca_nr_90orLarger >= 2, 1, 0)),
    ICAI_stenosis50 = factor(ifelse(ICAIAtherosclerosis == "Yes, >=50% stenosis", 1, 0)),
    AngleAaInn_OR_AaCca_dich45 = factor(ifelse(AngleAaInn_OR_AaCca > 45, 0, 1))
  ) %>% 
  CreateTableOne(data = ., strata = "dataset")

# Summaries of all continuous variables
invisible(
  capture.output(
    tab_contin <- print(
      x = table_one$ContTable, 
      nonnormal = TRUE, 
      noSpaces = TRUE
    )
  )
)

#https://stackoverflow.com/questions/50039186/add-download-buttons-in-dtrenderdatatable
DT::datatable(
  tab_contin,
  extensions = 'Buttons',
  options = list(
    dom = 'Blfrtip', 
    buttons = c('csv', 'excel', 'pdf'),
    lengthMenu = list(c(10, 25, 50, -1), c(10, 25, 50, "All"))
  )
)
```

For categorical variables:

```{r table-one-categ}
# Summaries of all categorical variables
invisible(
  capture.output(
    tab_cat <- print(
      x = table_one$CatTable, 
      nonnormal = TRUE, 
      noSpaces = TRUE
    )
  )
)

DT::datatable(
  tab_cat,
  extensions = 'Buttons',
  options = list(
    dom = 'Blfrtip', 
    buttons = c('csv', 'excel', 'pdf'),
    lengthMenu = list(c(10, 25, 50, -1), c(10, 25, 50, "All"))
  )
)
```

### Missing data summaries 


```{r cca-check}
# Seperate datasets
dat_develop <- subset(x = dat_to_impute, select = -dataset, subset = (dataset == "develop"))

dat_valid <- subset(x = dat_to_impute, select = -dataset, subset = (dataset == "valid"))

# Development
prop_cca_dev <- mean(complete.cases(dat_develop[, c("Mc_FailedFemoralApproach", candidate_predictors)]))

# Validation
prop_cca_valid <- mean(complete.cases(dat_valid[, c("Mc_FailedFemoralApproach", candidate_predictors)]))

# Combined
prop_cca_comb <- mean(complete.cases(dat_to_impute[, c("Mc_FailedFemoralApproach", candidate_predictors)]))
```

Complete-case analysis (using predictors in the prediction model) results in:

- `r paste0(round(prop_cca_dev * 100, 2), " %")` complete cases in the development data
- `r paste0(round(prop_cca_valid * 100, 2), " %")` complete cases in the validation data
- `r paste0(round(prop_cca_comb * 100, 2), " %")` complete cases in the combined data

```{r miss-dat-summ}
# Visualise missings beforehand
naniar::gg_miss_var(dat_to_impute, facet = dataset, show_pct = TRUE)
naniar::gg_miss_upset(dat_valid, nsets = 10)
naniar::gg_miss_upset(dat_develop, nsets = 10)
```

<!-- (Naniar/JointAI summaries/VIM) -->

## Internal validation development set

```{r dev-coefs}
# Development imputation
imps_develop <- imps_all %>% 
  filter(imps_label == "imps_assess" & dataset == "develop")

# Development model
mod_develop <- validation_dev_lambdamin$model_fit
mod_coefs <- as.matrix(coef(mod_develop))
colnames(mod_coefs) <- "Coefficients"

# Print penalised model coefficients
#knitr::kable(data.frame(mod_coefs))
DT::datatable(
  data.frame(round(mod_coefs, digits = 3)),
  extensions = 'Buttons',
  options = list(
    dom = 'Blfrtip', 
    buttons = c('csv', 'excel', 'pdf'),
    lengthMenu = list(c(10, 25, 50, -1), c(10, 25, 50, "All"))
  )
)
```

Bootstrap-based internal validation, optimism-corrected performance:

```{r valid-dev}
# Optimism corrected
validation_dev_lambdamin$validation_summary %>% 
  filter(measure %in% c("auc", "intercept", "slope")) %>% 
  group_by(measure) %>% 
  summarise(value = paste0(corrected, " [", lower_corrected, ";", upper_corrected, "]")) %>%
  knitr::kable()
```

Calibration plot (apparent)

```{r dev-calib}
calplot_MI(
  imps_long = imps_all %>% 
    filter(imps_label == "imps_assess" & dataset == "develop"),
  model = validation_dev_lambdamin$model_fit,
  impdat_ind = ".imp",
  model_formula = model_formula,
  height_hist = 0.2,
  startpos_hist = -0.25,
  knots = 5,
  n_bins = 100,
  xlim = c(0, 0.85),
  ylim = c(-0.25, 1)
) +
  theme_minimal()
```

## External validation

```{r ext-validation}
imps_valid <- imps_all %>% 
  filter(imps_label == "imps_assess" & dataset == "valid")

X_valid <- subset(x = stats::model.matrix(model_formula, data = imps_valid), select = -`(Intercept)`)

# Compute linear predictor
lp_valid <- drop(predict(mod_develop, newx = X_valid))
df_calplot_valid <- cbind.data.frame(lp_valid, imps_valid)

# Pool AUC
auc_df <- split(df_calplot_valid, ~ .imp) %>%
  map(.f = ~ {
    auc_obj <- pROC::auc(Mc_FailedFemoralApproach ~ lp_valid, data = .x)
    cbind.data.frame("auc" = as.numeric(auc_obj), "var_auc" = pROC::var(auc_obj))
  }) %>%
  bind_rows(.id = ".imp") 

auc_ext <- psfmi::pool_auc(
  est_auc = auc_df$auc,
  est_se = sqrt(auc_df$var_auc),
  nimp = max(as.numeric(auc_df$.imp))
)

# Get cal slope and intercept
cal_slope_ext <- split(df_calplot_valid, ~ .imp) |> 
  map(.f = ~ glm(Mc_FailedFemoralApproach ~ lp_valid, family = binomial, data = .x)) |> 
  mice::pool() |> 
  summary(conf.int = TRUE)

cal_int_ext <- split(df_calplot_valid, ~ .imp) |> 
  map(.f = ~ glm(Mc_FailedFemoralApproach ~ offset(lp_valid), family = binomial, data = .x)) |> 
  mice::pool() |> 
  summary(conf.int = TRUE)

int_ext <- with(
  cal_int_ext, 
  paste0(
    round(estimate, 3), " [",
    round(`2.5 %`, 3), ", ",
    round(`97.5 %`, 3), "]"
  )
)

slope_ext <- with(
  cal_slope_ext[2, ], 
  paste0(
    round(estimate, 3), " [",
    round(`2.5 %`, 3), ", ",
    round(`97.5 %`, 3), "]"
  )
)

auc_ext_bis <- with(
  as.data.frame(auc_ext),
  paste0(
    round(`C-statistic`, 3), " [",
    round(`95% Low`, 3), ", ",
    round(`95% Up`, 3), "]"
  )
)

rbind.data.frame(
  cbind.data.frame("measure" = "auc", "value" = auc_ext_bis),
  cbind.data.frame("measure" = "intercept", "value" = int_ext),
  cbind.data.frame("measure" = "slope", "value" = slope_ext)
)

# Overestimation of risks
calplot_MI(
  imps_long = imps_valid,
  model = validation_dev_lambdamin$model_fit,
  impdat_ind = ".imp",
  model_formula = model_formula,
  height_hist = 0.2,
  startpos_hist = -0.25,
  knots = 5,
  n_bins = 200,
  xlim = c(0, 0.85),
  ylim = c(-0.25, 1)
) +
  theme_minimal()
```

## Model update: combined cohort re-estimation

### Interaction-by-cohort (unpenalized)

(Ewout reference here, article)

```{r interaction-by-cohort}
imps_combined <- imps_all %>% 
  filter(imps_label == "imps_combined")

split(imps_combined, ~ .imp) |> 
  map(.f = ~ glm(update(model_formula, . ~ . * dataset), family = binomial, data = .x)) |> 
  mice::pool() |> 
  broom::tidy() |>  
  ggforestplot::forestplot(
    name = term,
    estimate = estimate,
    se = std.error
  )

split(imps_combined, ~ .imp) |> 
  map(.f = ~ glm(update(model_formula, . ~ . * dataset), family = binomial, data = .x)) |> 
  mice::pool() |> 
  broom::tidy() |> 
  select(term, estimate)

split(imps_combined |> filter(dataset == "develop"), ~ .imp) |> 
  map(.f = ~ glm(model_formula, family = binomial, data = .x)) |> 
  mice::pool() |> 
  broom::tidy() |> 
  pull(estimate)

cbind.data.frame(
  split(imps_combined, ~ .imp) |> 
  map(.f = ~ glm(update(model_formula, . ~ . * dataset), family = binomial, data = .x)) |> 
  mice::pool() |> 
  broom::tidy() |> 
  select(term, estimate),
  "develop" = split(imps_combined |> filter(dataset == "develop"), ~ .imp) |> 
  map(.f = ~ glm(model_formula, family = binomial, data = .x)) |> 
  mice::pool() |> 
  broom::tidy() |> 
  pull(estimate),
  "valid" =  split(imps_combined |> filter(dataset == "valid"), ~ .imp) |> 
  map(.f = ~ glm(model_formula, family = binomial, data = .x)) |> 
  mice::pool() |> 
  broom::tidy() |> 
  pull(estimate),
  "combined" =  split(imps_combined, ~ .imp) |> 
  map(.f = ~ glm(model_formula, family = binomial, data = .x)) |> 
  mice::pool() |> 
  broom::tidy() |> 
  pull(estimate)
) |> 
  View()

# ORs
cbind.data.frame(
  split(imps_combined, ~ .imp) |> 
  map(.f = ~ glm(update(model_formula, . ~ . * dataset), family = binomial, data = .x)) |> 
  mice::pool() |> 
  broom::tidy(exponentiate = TRUE) |> 
  select(term, estimate),
  "develop" = split(imps_combined |> filter(dataset == "develop"), ~ .imp) |> 
  map(.f = ~ glm(model_formula, family = binomial, data = .x)) |> 
  mice::pool() |> 
  broom::tidy(exponentiate = TRUE) |> 
  pull(estimate),
  "valid" =  split(imps_combined |> filter(dataset == "valid"), ~ .imp) |> 
  map(.f = ~ glm(model_formula, family = binomial, data = .x)) |> 
  mice::pool() |> 
  broom::tidy(exponentiate = TRUE) |> 
  pull(estimate),
  "combined" =  split(imps_combined, ~ .imp) |> 
  map(.f = ~ glm(model_formula, family = binomial, data = .x)) |> 
  mice::pool() |> 
  broom::tidy(exponentiate = TRUE) |> 
  pull(estimate)
) |> 
  View()

model.matrix(model_formula, data=imps_combined) %>% 
  cor(use="pairwise.complete.obs") %>% 
  ggcorrplot::ggcorrplot(show.diag = F, type="lower", lab=TRUE, lab_size=2)
```

### Internal validation combined cohort

```{r combined-validation}
mod_combined <- validation_comb_lambdamin$model_fit
#validation_comb_lambdamin$model_fit$lambda

mod_coefs_comb <- as.matrix(coef(mod_combined))
colnames(mod_coefs_comb) <- "Coefficients"

# Print penalied model coefficients
knitr::kable(data.frame(mod_coefs_comb))

validation_comb_lambdamin$validation_summary
validation_comb_lambdamin$validation_df |> 
  ggplot(aes(x = corrected)) +
  geom_histogram(bins = 50) +
  facet_wrap(~ measure, scales = "free")

validation_comb_lambdamin$validation_df |> 
  group_by(boot_num) |> 
  summarise(pen = mean(penalty)) |>
  #pull(pen) |>  mean()
  ggplot(aes(pen)) +
  geom_histogram()

calplot_MI(
  imps_long = imps_combined,
  model = validation_comb_lambdamin$model_fit,
  impdat_ind = ".imp",
  model_formula = model_formula,
  height_hist = 0.2,
  startpos_hist = -0.25,
  knots = 5,
  n_bins = 200,
  xlim = c(0, 0.55),
  ylim = c(-0.25, 0.8)
) +
  theme_minimal()
```

### Nomogram


