---
title: "Article results"
author: "E. F. Bonneville"
date: "`r Sys.setenv(LANG = 'en_US.UTF-8'); format(Sys.Date(), '%d %B %Y')`"
output: 
  html_document:
    df_print: kable
    toc: yes
    toc_float: 
      smooth_scroll: false
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_knit$set(root.dir = here::here())
knitr::opts_chunk$set(
  echo = FALSE, 
  out.width = "100%", 
  warning = FALSE, 
  message = FALSE
)

# Load libraries for knitting
library(ggplot2)
library(targets)
library(tidyverse)
library(tableone)

# Source functions
source("data-raw/prepare_raw_data.R")
source("R/imputation-helpers.R")
source("R/model-validation-helpers.R")
source("R/calplot-MI.R")

# Set contrasts for ordered factors
options(contrasts = rep("contr.treatment", 2))

# Set global setting
theme_set(theme_minimal(base_size = 14))
```

```{r objs}
tar_load(
  c(
    dat_combined,
    dat_to_impute,
    imps_all,
    candidate_predictors,
    model_formula,
    analysis_settings,
    validation_dev_lambdamin,
    validation_comb_lambdamin
  )
)

# For later use
response_var <- all.vars(stats::update(model_formula, . ~ 1))
```

## Descriptives

### Table 1

For continous variables:

```{r table-one-contin}
# Gives you everything for tables 1 and 2 (warnings due to variables not in validation, ignore!)
table_one <- dat_combined %>%  
  select(-all_of(c("sidescored", "AngleCcaIca", "ICAEAtherosclerosis", "StudySubjectID"))) %>%
  # Here we dichotomise purely for the table, does not affect original data
  mutate(
    ICA_nr_90orLarger_geq1 = factor(ifelse(ICA_nr_90orLarger >= 1, 1, 0)),
    ICA_nr_90orLarger_geq2 = factor(ifelse(ICA_nr_90orLarger >= 2, 1, 0)),
    ICAE_NASCET_99 = factor(ifelse(ICAE_NASCET_Degree < 99, 0,1)),
    InnCca_90orLarger_geq1 = factor(ifelse(InnCca_nr_90orLarger >= 1, 1, 0)),
    InnCca_90orLarger_geq2 = factor(ifelse(InnCca_nr_90orLarger >= 2, 1, 0)),
    ICAI_stenosis50 = factor(ifelse(ICAIAtherosclerosis == "Yes, >=50% stenosis", 1, 0)),
    AngleAaInn_OR_AaCca_dich45 = factor(ifelse(AngleAaInn_OR_AaCca > 45, 0, 1))
  ) %>% 
  CreateTableOne(data = ., strata = "dataset")

# Summaries of all continuous variables
kableone(table_one$ContTable, nonnormal = TRUE)
```

For categorical variables:

```{r table-one-categ}
# Summaries of all categorical variables
kableone(table_one$CatTable)
```

### Missing data summaries 

```{r miss-dat-summ}
# Seperate datasets
dat_develop <- subset(x = dat_to_impute, select = -dataset, subset = (dataset == "develop"))
dat_valid <- subset(x = dat_to_impute, select = -dataset, subset = (dataset == "valid"))

# Check proportion of complete cases in target analysis (quite good, compare results)
mean(complete.cases(dat_develop[, c("Mc_FailedFemoralApproach", candidate_predictors)]))
mean(complete.cases(dat_valid[, c("Mc_FailedFemoralApproach", candidate_predictors)]))
mean(complete.cases(dat_to_impute[, c("Mc_FailedFemoralApproach", candidate_predictors)]))

# Visualise missings beforehand
naniar::gg_miss_var(dat_to_impute, facet = dataset, show_pct = TRUE)
naniar::gg_miss_upset(dat_valid, nsets = 10)
naniar::gg_miss_upset(dat_develop, nsets = 10)
```

<!-- (Naniar/JointAI summaries/VIM) -->

## Internal validation development set

```{r dev-coefs}
# Development imputation
imps_develop <- imps_all %>% 
  filter(imps_label == "imps_assess" & dataset == "develop")

# Development model
mod_develop <- validation_dev_lambdamin$model_fit
mod_coefs <- as.matrix(coef(mod_develop))
colnames(mod_coefs) <- "Coefficients"

# Print penalied model coefficients
knitr::kable(data.frame(mod_coefs))
```

Bootstrap-based internal validation, optimism-corrected performance:

```{r valid-dev}
# Optimism corrected
validation_dev_lambdamin$validation_summary %>% 
  filter(measure %in% c("auc", "intercept", "slope")) %>% 
  group_by(measure) %>% 
  summarise(value = paste0(corrected, " [", lower_corrected, ";", upper_corrected, "]")) %>%
  knitr::kable()
```

Calibration plot (apparent)

```{r dev-calib}
calplot_MI(
  imps_long = imps_all %>% 
    filter(imps_label == "imps_assess" & dataset == "develop"),
  model = validation_dev_lambdamin$model_fit,
  impdat_ind = ".imp",
  model_formula = model_formula,
  height_hist = 0.2,
  startpos_hist = -0.25,
  knots = 5,
  n_bins = 100,
  xlim = c(0, 0.85),
  ylim = c(-0.25, 1)
) +
  theme_minimal()
```

## External validation

```{r ext-validation}
imps_valid <- imps_all %>% 
  filter(imps_label == "imps_assess" & dataset == "valid")

X_valid <- subset(x = stats::model.matrix(model_formula, data = imps_valid), select = -`(Intercept)`)

# Compute linear predictor
lp_valid <- drop(predict(mod_develop, newx = X_valid))
df_calplot_valid <- cbind.data.frame(lp_valid, imps_valid)

# Pool AUC
auc_df <- split(df_calplot_valid, ~ .imp) %>%
  map(.f = ~ {
    auc_obj <- pROC::auc(Mc_FailedFemoralApproach ~ lp_valid, data = .x)
    cbind.data.frame("auc" = as.numeric(auc_obj), "var_auc" = pROC::var(auc_obj))
  }) %>%
  bind_rows(.id = ".imp") 

psfmi::pool_auc(auc_df$auc, sqrt(auc_df$var_auc), nimp = max(as.numeric(auc_df$.imp)))

# Get cal slope and intercept
split(df_calplot_valid, ~ .imp) |> 
  map(.f = ~ glm(Mc_FailedFemoralApproach ~ lp_valid, family = binomial, data = .x)) |> 
  mice::pool() |> 
  summary()

split(df_calplot_valid, ~ .imp) |> 
  map(.f = ~ glm(Mc_FailedFemoralApproach ~ offset(lp_valid), family = binomial, data = .x)) |> 
  mice::pool() |> 
  summary()

# Overestimation of risks
calplot_MI(
  imps_long = imps_valid,
  model = validation_dev_lambdamin$model_fit,
  impdat_ind = ".imp",
  model_formula = model_formula,
  height_hist = 0.2,
  startpos_hist = -0.25,
  knots = 5,
  n_bins = 200,
  xlim = c(0, 0.85),
  ylim = c(-0.25, 1)
) +
  theme_minimal()
```

## Model update 1: logistic recalibration

```{r log-recal}
# 
imps_valid$lp_valid <- lp_valid
mod_recal <- glm(
  Mc_FailedFemoralApproach ~ lp_valid, 
  family = binomial(), 
  data = imps_valid
)
boots_valid <- group_resample(imps_valid, id_var = ".id", 
                              B = 50, 
    boot_id_name = ".id_boot")

boots_cals <- map_dfr(boots_valid, function(boot_dat) {
  mod_recal_boot <- glm(
  Mc_FailedFemoralApproach ~ lp_valid, 
  family = binomial(), 
  data = boot_dat
)
  calibration_intercept_slope(
    imps_valid$Mc_FailedFemoralApproach, predict(mod_recal_boot, newdata = imps_valid)
  )
})
colMeans(boots_cals)

# Calib plot
library(splines)
ggplot() +
  geom_smooth(
    data = cbind.data.frame(
      "predicted" = predict(mod_recal, type = "response"), #wrrooong
      "outcome" = as.numeric(imps_valid$Mc_FailedFemoralApproach) - 1L,
      "imp" = imps_valid$.imp
    ),
    aes(
      x = predicted,
      y = outcome,
      group = imp
    ), method = "glm",
    formula = y ~ ns(x, 5),
    method.args = list(family = "binomial"),
    se = FALSE,
    col = "gray",
    alpha = 0.7
  ) +
  geom_abline(intercept = 0, slope = 1) +
  lims(x = c(0, 1), y = c(0, 1))
```

## Model update 2: combined cohort re-estimation

### Interaction-by-cohort (unpenalized)

(Ewout reference here, article)


```{r interaction-by-cohort}
split(imps_combined, ~ .imp) |> 
  map(.f = ~ glm(update(model_formula, . ~ . * dataset), family = binomial, data = .x)) |> 
  mice::pool() |> 
  broom::tidy() |>  
  ggforestplot::forestplot(
    name = term,
    estimate = estimate,
    se = std.error
  )

split(imps_combined, ~ .imp) |> 
  map(.f = ~ glm(update(model_formula, . ~ . * dataset), family = binomial, data = .x)) |> 
  mice::pool() |> 
  broom::tidy() |> 
  select(term, estimate)

split(imps_combined |> filter(dataset == "develop"), ~ .imp) |> 
  map(.f = ~ glm(model_formula, family = binomial, data = .x)) |> 
  mice::pool() |> 
  broom::tidy() |> 
  pull(estimate)

cbind.data.frame(
  split(imps_combined, ~ .imp) |> 
  map(.f = ~ glm(update(model_formula, . ~ . * dataset), family = binomial, data = .x)) |> 
  mice::pool() |> 
  broom::tidy() |> 
  select(term, estimate),
  "develop" = split(imps_combined |> filter(dataset == "develop"), ~ .imp) |> 
  map(.f = ~ glm(model_formula, family = binomial, data = .x)) |> 
  mice::pool() |> 
  broom::tidy() |> 
  pull(estimate),
  "valid" =  split(imps_combined |> filter(dataset == "valid"), ~ .imp) |> 
  map(.f = ~ glm(model_formula, family = binomial, data = .x)) |> 
  mice::pool() |> 
  broom::tidy() |> 
  pull(estimate),
  "combined" =  split(imps_combined, ~ .imp) |> 
  map(.f = ~ glm(model_formula, family = binomial, data = .x)) |> 
  mice::pool() |> 
  broom::tidy() |> 
  pull(estimate)
) |> 
  View()

# ORs
cbind.data.frame(
  split(imps_combined, ~ .imp) |> 
  map(.f = ~ glm(update(model_formula, . ~ . * dataset), family = binomial, data = .x)) |> 
  mice::pool() |> 
  broom::tidy(exponentiate = TRUE) |> 
  select(term, estimate),
  "develop" = split(imps_combined |> filter(dataset == "develop"), ~ .imp) |> 
  map(.f = ~ glm(model_formula, family = binomial, data = .x)) |> 
  mice::pool() |> 
  broom::tidy(exponentiate = TRUE) |> 
  pull(estimate),
  "valid" =  split(imps_combined |> filter(dataset == "valid"), ~ .imp) |> 
  map(.f = ~ glm(model_formula, family = binomial, data = .x)) |> 
  mice::pool() |> 
  broom::tidy(exponentiate = TRUE) |> 
  pull(estimate),
  "combined" =  split(imps_combined, ~ .imp) |> 
  map(.f = ~ glm(model_formula, family = binomial, data = .x)) |> 
  mice::pool() |> 
  broom::tidy(exponentiate = TRUE) |> 
  pull(estimate)
) |> 
  View()

model.matrix(model_formula, data=imps_combined) %>% 
  cor(use="pairwise.complete.obs") %>% 
  ggcorrplot::ggcorrplot(show.diag = F, type="lower", lab=TRUE, lab_size=2)
```

### Internal validation combined cohort

```{r combined-validation}
imps_combined <- imps_all %>% 
  filter(imps_label == "imps_combined")

mod_combined <- validation_comb_lambdamin$model_fit
validation_comb_lambdamin$model_fit$lambda
mod_combined$beta

validation_comb_lambdamin$validation_summary
validation_comb_lambdamin$validation_df |> 
  ggplot(aes(x = corrected)) +
  geom_histogram(bins = 50) +
  facet_wrap(~ measure, scales = "free")

validation_comb_lambdamin$validation_df |> 
  group_by(boot_num) |> 
  summarise(pen = mean(penalty)) |>
  #pull(pen) |>  mean()
  ggplot(aes(pen)) +
  geom_histogram()

calplot_MI(
  imps_long = imps_combined,
  model = validation_comb_lambdamin$model_fit,
  impdat_ind = ".imp",
  model_formula = model_formula,
  height_hist = 0.2,
  startpos_hist = -0.25,
  knots = 5,
  n_bins = 200,
  xlim = c(0, 0.55),
  ylim = c(-0.25, 0.8)
) +
  theme_minimal()

# Try simpler version of cal plot
lp_combined <- predict(
  validation_comb_lambdamin$model_fit,
  newx = subset(
    x = model.matrix(model_formula, data = imps_combined), 
    select = -`(Intercept)`
  )
)

df <- cbind.data.frame(
      "predicted" = drop(lp_combined),
      "outcome" = as.numeric(imps_combined$Mc_FailedFemoralApproach) - 1L,
      "imp" = imps_combined$.imp
    )

binomial_smooth <- function(...) {
  geom_smooth(method = "glm", method.args = list(family = "binomial"), ...)
}

ggplot(data = df, aes(plogis(predicted), outcome)) +
  binomial_smooth(
    aes(x = predicted),
    formula = y ~ splines::ns(x, 3),
    se = FALSE
  ) #+
  scale_x_continuous(trans = "log", limits = c(0.1, 1))
  geom_smooth(
    ,
    aes(
      x = predicted,
      y = outcome#,
      #group = imp
    ), 
    method = "glm",
    #formula = y ~ splines::ns(x, 3),
    method.args = list(family = "binomial"),
    se = FALSE,
    col = "gray",
    alpha = 0.7
  ) +
  geom_abline(intercept = 0, slope = 1) +
  lims(x = c(0, 1), y = c(0, 1))




```

### Nomogram