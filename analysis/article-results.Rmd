---
title: "Article results"
author: "E. F. Bonneville"
date: "`r Sys.setenv(LANG = 'en_US.UTF-8'); format(Sys.Date(), '%d %B %Y')`"
output: 
  html_document:
    df_print: kable
    toc: yes
    toc_float: 
      smooth_scroll: false
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_knit$set(root.dir = here::here())
knitr::opts_chunk$set(
  echo = FALSE, 
  out.width = "100%", 
  warning = FALSE, 
  message = FALSE
)

# Load libraries for knitting
library(ggplot2)
library(targets)
library(tidyverse)
library(tableone)

# Source functions
source("data-raw/prepare_raw_data.R")
source("R/imputation-helpers.R")
source("R/model-validation-helpers.R")
source("R/calplot-MI.R")

# Set contrasts for ordered factors
options(contrasts = rep("contr.treatment", 2))

# Set global setting
theme_set(theme_minimal(base_size = 14))
```

```{r objs}
tar_load(
  c(
    dat_combined,
    dat_to_impute,
    imps_all,
    candidate_predictors,
    model_formula,
    analysis_settings,
    validation_dev_lambdamin,
    validation_comb_lambdamin
  )
)

# For later use
response_var <- all.vars(stats::update(model_formula, . ~ 1))
```

## Descriptives

### Table 1

For continous variables:

```{r table-one-contin}
# Gives you everything for tables 1 and 2 (warnings due to variables not in validation, ignore!)
table_one <- dat_combined %>%  
  select(-all_of(c("sidescored", "AngleCcaIca", "ICAEAtherosclerosis", "StudySubjectID"))) %>%
  # Here we dichotomise purely for the table, does not affect original data
  mutate(
    ICA_nr_90orLarger_geq1 = factor(ifelse(ICA_nr_90orLarger >= 1, 1, 0)),
    ICA_nr_90orLarger_geq2 = factor(ifelse(ICA_nr_90orLarger >= 2, 1, 0)),
    ICAE_NASCET_99 = factor(ifelse(ICAE_NASCET_Degree < 99, 0,1)),
    InnCca_90orLarger_geq1 = factor(ifelse(InnCca_nr_90orLarger >= 1, 1, 0)),
    InnCca_90orLarger_geq2 = factor(ifelse(InnCca_nr_90orLarger >= 2, 1, 0)),
    ICAI_stenosis50 = factor(ifelse(ICAIAtherosclerosis == "Yes, >=50% stenosis", 1, 0)),
    AngleAaInn_OR_AaCca_dich45 = factor(ifelse(AngleAaInn_OR_AaCca > 45, 0, 1))
  ) %>% 
  CreateTableOne(data = ., strata = "dataset")

# Summaries of all continuous variables
kableone(table_one$ContTable, nonnormal = TRUE)
```

For categorical variables:

```{r table-one-categ}
# Summaries of all categorical variables
kableone(table_one$CatTable)
```

### Missing data summaries 

```{r miss-dat-summ}
# Seperate datasets
dat_develop <- subset(x = dat_to_impute, select = -dataset, subset = (dataset == "develop"))
dat_valid <- subset(x = dat_to_impute, select = -dataset, subset = (dataset == "valid"))

# Check proportion of complete cases in target analysis (quite good, compare results)
mean(complete.cases(dat_develop[, c("Mc_FailedFemoralApproach", candidate_predictors)]))
mean(complete.cases(dat_valid[, c("Mc_FailedFemoralApproach", candidate_predictors)]))
mean(complete.cases(dat_to_impute[, c("Mc_FailedFemoralApproach", candidate_predictors)]))

# Visualise missings beforehand
naniar::gg_miss_var(dat_to_impute, facet = dataset, show_pct = TRUE)
naniar::gg_miss_upset(dat_valid, nsets = 10)
naniar::gg_miss_upset(dat_develop, nsets = 10)
```

(Naniar/JointAI summaries/VIM)

## Internal validation development set

```{r dev-coefs}
# Development imputation
imps_develop <- imps_all %>% 
  filter(imps_label == "imps_assess" & dataset == "develop")

# Development model
mod_develop <- validation_dev_lambdamin$model_fit
mod_coefs <- as.matrix(coef(mod_develop))
colnames(mod_coefs) <- "Coefficients"

knitr::kable(data.frame(mod_coefs))
```

```{r valid-dev}
# Optimism corrected
validation_dev_lambdamin$validation_summary %>% 
  filter(measure %in% c("auc", "intercept", "slope")) %>% 
  group_by(measure) %>% 
  summarise(value = paste0(corrected, " [", lower_corrected, ";", upper_corrected, "]")) %>%
  knitr::kable()
```

```{r dev-calib}
calplot_MI(
  imps_long = imps_all %>% 
    filter(imps_label == "imps_assess" & dataset == "develop"),
  model = mod_develop_1se, #validation_dev_lambdamin$model_fit,
  impdat_ind = ".imp",
  model_formula = model_formula,
  height_hist = 0.2,
  startpos_hist = -0.25,
  knots = 5,
  n_bins = 100,
  xlim = c(0, 0.85),
  ylim = c(-0.25, 1)
) +
  theme_minimal()
```

## External validation

```{r ext-validation}
imps_valid <- imps_all %>% 
  filter(imps_label == "imps_assess" & dataset == "valid")

X_valid <- subset(x = stats::model.matrix(model_formula, data = imps_valid), select = -`(Intercept)`)


# 1 se test
folds <- assign_crossval_folds(y = unique(imps_develop[[".id"]]), n_folds = 10)
cross_val <- glmnet::cv.glmnet(
    x = subset(x = stats::model.matrix(model_formula, data = imps_develop), select = -`(Intercept)`),
    y = imps_develop$Mc_FailedFemoralApproach,
    wts = imps_develop$wts,
    foldid = folds[match(imps_develop[[".id"]], folds[["y"]]), "fold"],
    family = "binomial",
    alpha = 0
  )
plot(cross_val)

folds <- assign_crossval_folds(y = unique(imps_all[[".id"]]), n_folds = 10)

cross_val <- glmnet::cv.glmnet(
    x = subset(x = stats::model.matrix(model_formula, data = imps_all), select = -`(Intercept)`),
    y = imps_all$Mc_FailedFemoralApproach,
    wts = imps_all$wts,
    foldid = folds[match(imps_all[[".id"]], folds[["y"]]), "fold"],
    family = "binomial",
    alpha = 0
  )
cross_val$lambda
plot(cross_val)


mod_develop_1se <- run_stacked_glmnet(
    x = subset(x = stats::model.matrix(model_formula, data = imps_develop), select = -`(Intercept)`),
    y = imps_develop$Mc_FailedFemoralApproach,
    wts = imps_develop$wts,
    foldid = folds[match(imps_develop[[".id"]], folds[["y"]]), "fold"],
    lambda_choice = "1se",
    alpha = 0
  )
  

# Compute linear predictor
lp_valid <- drop(predict(mod_develop_1se, newx = X_valid))
df_calplot_valid <- cbind.data.frame(lp_valid, imps_valid)

# Pool AUC
auc_df <- split(df_calplot_valid, ~ .imp) %>%
  map(.f = ~ {
    auc_obj <- pROC::auc(Mc_FailedFemoralApproach ~ lp_valid, data = .x)
    cbind.data.frame("auc" = as.numeric(auc_obj), "var_auc" = pROC::var(auc_obj))
  }) %>%
  bind_rows(.id = ".imp") 

psfmi::pool_auc(auc_df$auc, sqrt(auc_df$var_auc), nimp = max(as.numeric(auc_df$.imp)))

# Get cal slope and intercept
split(df_calplot_valid, ~ .imp) |> 
  map(.f = ~ glm(Mc_FailedFemoralApproach ~ lp_valid, family = binomial, data = .x)) |> 
  mice::pool() |> 
  summary()

split(df_calplot_valid, ~ .imp) |> 
  map(.f = ~ glm(Mc_FailedFemoralApproach ~ offset(lp_valid), family = binomial, data = .x)) |> 
  mice::pool() |> 
  summary()

calplot_MI(
  imps_long = imps_valid,
  model = mod_develop_1se, #validation_dev_lambdamin$model_fit,
  impdat_ind = ".imp",
  model_formula = model_formula,
  height_hist = 0.2,
  startpos_hist = -0.25,
  knots = 5,
  n_bins = 200,
  xlim = c(0, 0.85),
  ylim = c(-0.25, 1)
) +
  theme_minimal()
```


Try intermediate updating with logreg recalibration

```{r updating}
# 
mod_recal <- split(df_calplot_valid, ~ .imp) |> 
  map(.f = ~ glm(Mc_FailedFemoralApproach ~ lp_valid, family = binomial, data = .x)) |> 
  mice::pool() |> 
  summary()
coefs_mod_recal <- mod_recal$estimate
new_coefs <- drop(coefs_mod_recal[2] * mod_coefs[-1])
new_coefs <- c(mod_coefs[1] + coefs_mod_recal[1], new_coefs) #new_coefs[1] - 0.1059395 #+ coefs_mod_recal[1]
new_lp <- drop((new_coefs) %*% t(cbind(1, X_valid)))

library(Hmisc)
library(rms)

dd <- datadist(imps_valid %>% select(all_of(c(response_var, candidate_predictors)))); 
options(datadist = "dd")

CalibrationCurves::val.prob.ci.2(
  y = (as.numeric(imps_valid$Mc_FailedFemoralApproach) - 1)[1:30000],
  logit = (lp_valid)[1:30000], 
  smooth = FALSE,
  CL.smooth	= FALSE,
  CL.BT	= FALSE,
  logistic.cal = TRUE,
  #g = 10,
  dostats = FALSE
)

df_calplot <- cbind.data.frame("lp_recal" = new_lp, imps_valid)
knots <- 4
#smooth_form <- reformulate(response = response_var, termlabels = paste0("splines::ns(lp, ", knots, ")"))
mod_cal_stacked <- glm(Mc_FailedFemoralApproach ~ ns(lp_recal, 4), data = df_calplot, family = binomial())
stacked_df <- data.frame(
    "predicted" = seq(0.01, 1, by = 0.01),
    "observed" = predict(mod_cal_stacked, 
                         newdata = data.frame("lp_recal" = seq(0.01, 1, by = 0.01)), 
                         type = "response")
)
plot(stacked_df$predicted, stacked_df$observed, xlim = c(0, 1), ylim = c(0, 1))

# Try other

# Try first all in one imp dataset
imp1 <- subset(df_calplot_valid, .imp == 1)

# See https://darrendahly.github.io/post/homr/
m1 <- glm(Mc_FailedFemoralApproach ~ offset(lp_valid), data = imp1, family = binomial())
m2 <- glm(Mc_FailedFemoralApproach ~ lp_valid, data = imp1, family = binomial())
imp1$pred_m1 <- predict(m1, type = "response")
imp1$pred_m2 <- predict(m2, type = "response")

ggplot(data = imp1) +
  geom_smooth(
    aes(x = pred_m1, y = as.numeric(Mc_FailedFemoralApproach) - 1), 
                  color = "red", se = FALSE, method = "loess"
  ) +
  geom_smooth(
    aes(x = plogis(lp_valid), y = as.numeric(Mc_FailedFemoralApproach) - 1), 
                  color = "black", se = FALSE, method = "loess"
  ) + 
  geom_smooth(
    aes(x = pred_m2, y = as.numeric(Mc_FailedFemoralApproach) - 1), 
                  color = "blue", se = FALSE, method = "loess"
  ) + 
  geom_abline(intercept = 0, slope = 1) +
  lims(x = c(0, 1), y = c(0, 1))

# Other tests 

```

## Updating to combined cohort

```{r combined-validation}
imps_combined <- imps_all %>% 
  filter(imps_label == "imps_combined")

mod_combined <- validation_comb_lambdamin$model_fit
validation_comb_lambdamin$model_fit$lambda
mod_combined$beta

validation_comb_lambdamin$validation_summary
validation_comb_lambdamin$validation_df |> 
  ggplot(aes(x = corrected)) +
  geom_histogram(bins = 50) +
  facet_wrap(~ measure, scales = "free")

validation_comb_lambdamin$validation_df |> 
  group_by(boot_num) |> 
  summarise(pen = mean(penalty)) |>
  #pull(pen) |>  mean()
  ggplot(aes(pen)) +
  geom_histogram()

calplot_MI(
  imps_long = imps_combined,
  model = validation_comb_lambdamin$model_fit,
  impdat_ind = ".imp",
  model_formula = model_formula,
  height_hist = 0.2,
  startpos_hist = -0.25,
  knots = 5,
  n_bins = 200,
  xlim = c(0, 0.55),
  ylim = c(-0.25, 0.8)
) +
  theme_minimal()

calplot_MI(
  imps_long = imps_combined,
  model = validation_comb_lambda1se$model_fit,
  impdat_ind = ".imp",
  model_formula = model_formula,
  height_hist = 0.2,
  startpos_hist = -0.25,
  knots = 3,
  n_bins = 200,
  xlim = c(0, 0.55),
  ylim = c(-0.25, 0.8)
) +
  theme_minimal()


# Try the 1se on combined:
imputations <- imps_combined
formula <- model_formula
n_folds = 10
wts <- "wts"
lambda_choice <- "1se"

response_var <- all.vars(stats::update(formula, . ~ 1))
  X_orig <- subset(x = stats::model.matrix(formula, data = imputations), select = -`(Intercept)`)
  y_orig <- imputations[[response_var]]
  wts_orig <- imputations[[wts]]
  
  folds <- assign_crossval_folds(y = unique(imputations[[".id"]]), n_folds = n_folds)
cross_val <- glmnet::cv.glmnet(
    x = X_orig,
    y = y_orig,
    weights = wts_orig,
    foldid = folds[match(imputations[[".id"]], folds[["y"]]), "fold"],
    family = "binomial", 
    alpha = 0
  )

plot(cross_val)
  
dat_combined |> 
  select(candidate_predictors, dataset) |>  
    #Mc_FailedFemoralApproach, dataset) |> 
  GGally::ggpairs(
    aes(col = dataset, fill = dataset)
  )
  
  
  # First apparent performance - no penalty..
mod <-glmnet::glmnet(
    x = X_orig,
    y = y_orig,
    weights = wts_orig,
    family = "binomial",
    #lambda = 0, # unpenalized
    lambda = cross_val$lambda.min,
    alpha = 0, #ridge
    intercept = TRUE
  )

hist(plogis(predict(mod, newx = X_orig)))
max(plogis(predict(mod, newx = X_orig)))
coef(mod)
coef(
  glm(model_formula, data = imps_combined, family = binomial())
)
calplot_MI(
  imps_long = imps_combined,
  model = mod,
  impdat_ind = ".imp",
  model_formula = model_formula,
  height_hist = 0.2,
  startpos_hist = -0.25,
  knots = 5,
  n_bins = 200,
  xlim = c(0, 1),
  ylim = c(-0.25, 1)
) +
  theme_minimal()


# No penalty
modo <- glm(
  model_formula, family = binomial(), data = imps_combined, weights = imps_combined$wts
)
```


```{r interaction-by-cohort}
split(imps_combined, ~ .imp) |> 
  map(.f = ~ glm(update(model_formula, . ~ . * dataset), family = binomial, data = .x)) |> 
  mice::pool() |> 
  broom::tidy() |>  
  ggforestplot::forestplot(
    name = term,
    estimate = estimate,
    se = std.error
  )

split(imps_combined, ~ .imp) |> 
  map(.f = ~ glm(update(model_formula, . ~ . * dataset), family = binomial, data = .x)) |> 
  mice::pool() |> 
  broom::tidy() |> 
  select(term, estimate)

split(imps_combined |> filter(dataset == "develop"), ~ .imp) |> 
  map(.f = ~ glm(model_formula, family = binomial, data = .x)) |> 
  mice::pool() |> 
  broom::tidy() |> 
  pull(estimate)

cbind.data.frame(
  split(imps_combined, ~ .imp) |> 
  map(.f = ~ glm(update(model_formula, . ~ . * dataset), family = binomial, data = .x)) |> 
  mice::pool() |> 
  broom::tidy() |> 
  select(term, estimate),
  "develop" = split(imps_combined |> filter(dataset == "develop"), ~ .imp) |> 
  map(.f = ~ glm(model_formula, family = binomial, data = .x)) |> 
  mice::pool() |> 
  broom::tidy() |> 
  pull(estimate),
  "valid" =  split(imps_combined |> filter(dataset == "valid"), ~ .imp) |> 
  map(.f = ~ glm(model_formula, family = binomial, data = .x)) |> 
  mice::pool() |> 
  broom::tidy() |> 
  pull(estimate),
  "combined" =  split(imps_combined, ~ .imp) |> 
  map(.f = ~ glm(model_formula, family = binomial, data = .x)) |> 
  mice::pool() |> 
  broom::tidy() |> 
  pull(estimate)
) |> 
  View()

# ORs
cbind.data.frame(
  split(imps_combined, ~ .imp) |> 
  map(.f = ~ glm(update(model_formula, . ~ . * dataset), family = binomial, data = .x)) |> 
  mice::pool() |> 
  broom::tidy(exponentiate = TRUE) |> 
  select(term, estimate),
  "develop" = split(imps_combined |> filter(dataset == "develop"), ~ .imp) |> 
  map(.f = ~ glm(model_formula, family = binomial, data = .x)) |> 
  mice::pool() |> 
  broom::tidy(exponentiate = TRUE) |> 
  pull(estimate),
  "valid" =  split(imps_combined |> filter(dataset == "valid"), ~ .imp) |> 
  map(.f = ~ glm(model_formula, family = binomial, data = .x)) |> 
  mice::pool() |> 
  broom::tidy(exponentiate = TRUE) |> 
  pull(estimate),
  "combined" =  split(imps_combined, ~ .imp) |> 
  map(.f = ~ glm(model_formula, family = binomial, data = .x)) |> 
  mice::pool() |> 
  broom::tidy(exponentiate = TRUE) |> 
  pull(estimate)
) |> 
  View()

model.matrix(model_formula, data=imps_combined) %>% 
  cor(use="pairwise.complete.obs") %>% 
  ggcorrplot::ggcorrplot(show.diag = F, type="lower", lab=TRUE, lab_size=2)
```

### Nomogram